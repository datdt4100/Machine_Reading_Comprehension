{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, collections, os, random, glob, math, string, re, torch\n",
    "import numpy as np\n",
    "import timeit\n",
    "from tqdm import trange, tqdm_notebook as tqdm \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers import WEIGHTS_NAME, BertConfig, BertForQuestionAnswering, BertTokenizerFast, BasicTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.models.bert.tokenization_bert import whitespace_tokenize\n",
    "from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
    "from transformers import RobertaConfig, RobertaForQuestionAnswering, RobertaTokenizer\n",
    "from transformers import XLMRobertaConfig, XLMRobertaForQuestionAnswering, XLMRobertaTokenizer\n",
    "from transformers import AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for the Squad dataset.\n",
    "    For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 qas_id,\n",
    "                 question_text,\n",
    "                 doc_tokens,\n",
    "                 orig_answer_text=None,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 is_impossible=None,\n",
    "                 answers=None):\n",
    "        self.qas_id = qas_id\n",
    "        self.question_text = question_text\n",
    "        self.doc_tokens = doc_tokens\n",
    "        self.orig_answer_text = orig_answer_text\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible\n",
    "        self.answers = answers\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"qas_id: %s\" % (self.qas_id)\n",
    "        s += \", question_text: %s\" % (\n",
    "            self.question_text)\n",
    "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "        if self.start_position:\n",
    "            s += \", start_position: %d\" % (self.start_position)\n",
    "        if self.start_position:\n",
    "            s += \", end_position: %d\" % (self.end_position)\n",
    "        if self.start_position:\n",
    "            s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "        if self.start_position:\n",
    "            s += \", answers: %r\" % (self.answers)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_squad_examples(input_file, is_training):\n",
    "    \"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"\n",
    "\n",
    "    with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "        source = json.load(reader)\n",
    "        input_data = source[\"data\"]\n",
    "        version = source[\"version\"]\n",
    "\n",
    "    def is_whitespace(c):\n",
    "        if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "            return True\n",
    "        return False\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "        for paragraph in entry[\"paragraphs\"]:\n",
    "            paragraph_text = paragraph[\"context\"].lower()\n",
    "            doc_tokens = []\n",
    "            char_to_word_offset = []\n",
    "            prev_is_whitespace = True\n",
    "            for c in paragraph_text:\n",
    "                if is_whitespace(c):\n",
    "                    prev_is_whitespace = True\n",
    "                else:\n",
    "                    if prev_is_whitespace:\n",
    "                        doc_tokens.append(c)\n",
    "                    else:\n",
    "                        doc_tokens[-1] += c\n",
    "                    prev_is_whitespace = False\n",
    "                char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                qas_id = qa[\"id\"]\n",
    "                question_text = qa[\"question\"]\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                orig_answer_text = None\n",
    "                is_impossible = False\n",
    "                answers = []\n",
    "                if is_training:\n",
    "                    if version == \"v2.0\":\n",
    "                        is_impossible = qa[\"is_impossible\"]\n",
    "                    if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "                        #print(entry[\"title\"], qas_id)\n",
    "                        raise ValueError(\n",
    "                            \"For training, each question should have exactly 1 answer.\")\n",
    "                    if not is_impossible:\n",
    "                        answer = qa[\"answers\"][0]\n",
    "                        orig_answer_text = answer[\"text\"].lower()\n",
    "                        answer_offset = answer[\"answer_start\"]\n",
    "                        answer_length = len(orig_answer_text)\n",
    "                        start_position = char_to_word_offset[answer_offset]\n",
    "                        end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
    "                        # Only add answers where the text can be exactly recovered from the\n",
    "                        # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "                        # stuff so we will just skip the example.\n",
    "                        #\n",
    "                        # Note that this means for training mode, every example is NOT\n",
    "                        # guaranteed to be preserved.\n",
    "                        actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n",
    "                        cleaned_answer_text = \" \".join(whitespace_tokenize(orig_answer_text))\n",
    "                        if actual_text.find(cleaned_answer_text) == -1:\n",
    "                            print(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                                            actual_text, cleaned_answer_text)\n",
    "                            continue\n",
    "                    else: \n",
    "                        start_position = -1\n",
    "                        end_position = -1\n",
    "                        orig_answer_text = \"\"\n",
    "                else:\n",
    "                    answers = qa[\"answers\"]\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position,\n",
    "                    is_impossible=is_impossible,\n",
    "                    answers=answers)\n",
    "                \n",
    "                #print(example)\n",
    "                #type(example)\n",
    "                #qas_id: uit_01__08947_13_1, \n",
    "                #question_text: Dân tộc nào có nhiều nét tương đồng nhất với dân tộc Ê Đê?, \n",
    "                #doc_tokens: [Người Ê đê và người Gia Rai vốn cùng nguồn gốc từ một tộc người Orang Đê cổ được ghi chép khá nhiều trong các bia ký Champa, Khmer,...Orang Đê có thể là nhóm mà người Ê đê và Gia Rai gọi là Mdhur, trong văn hóa Mdhur có chứa đựng nhiều yếu tố văn hoá trung gian giữa người Ê đê và Gia Rai. Trong văn hóa Mdhur trước kia còn tồn tại tục hỏa táng người chết và bỏ tro trong chum, ché sau đó mới mang chôn cất trong nhà mồ, đây có thể là ảnh hưởng của đạo Hin-đu từ người Chăm. Xét về phương diện người Mdhur là cội nguồn xuất phát của người Ê đê và Gia Rai hiện đại. Trong lịch sử Orang Đê đã từng tồn tại các tiểu quốc sơ khai, với sự cai trị của các Mtao, Pơ Tao có thế lực trên một khu vực rộng lớn ở vùng người Gia Rai và Ê đê. Sự hình thành các tiểu quốc nhỏ là đặc điểm thường thấy ở các tộc người Đông Nam á:], \n",
    "                #start_position: 5, \n",
    "                #end_position: 6, \n",
    "                #is_impossible: False, \n",
    "                #answers: []\n",
    "\n",
    "                examples.append(example)\n",
    "                \n",
    "\n",
    "                #Ranking examples\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_squad_examples(r'D:\\NLP_project\\data\\SQuA2.0\\train-v2.0-vi.json', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qas_id: 0-1, question_text: Beyonce bắt đầu nổi tiếng từ khi nào?, doc_tokens: [beyoncé giselle knowles-carter (/ b i gì ɒ n s eɪ / bee-yon-say) (sinh ngày 04 tháng 9 1981) là một ca sĩ, nhạc sĩ, nhà sản xuất thu âm và nữ diễn viên người mỹ. sinh ra và lớn lên ở houston, texas, cô đã biểu diễn trong các cuộc thi ca hát và nhảy múa khác nhau khi còn nhỏ, và nổi tiếng vào cuối những năm 1990 với tư cách là ca sĩ chính của nhóm nhạc nữ r & b destiny's child. được quản lý bởi cha cô, mathew knowles, nhóm đã trở thành một trong những nhóm nhạc nữ bán chạy nhất thế giới mọi thời đại. sự gián đoạn của họ đã chứng kiến việc phát hành album đầu tay của beyoncé, dangerously in love (2003), giúp cô trở thành một nghệ sĩ solo trên toàn thế giới, giành được năm giải grammy và có đĩa đơn quán quân billboard hot 100 \"crazy in love\" và \"baby boy\".], start_position: 55, end_position: 56, is_impossible: False, answers: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'D:\\NLP_project\\data\\SQuA2.0\\train-v2.0.json'\n",
    "with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "    source = json.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source['data'][0]['paragraphs'][0]['qas'][0]['is_impossible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'D:\\NLP_project\\data\\SQuA2.0\\test-v2.0-preprocessed.json'\n",
    "with open(input_file, \"r\", encoding='utf-8') as reader:\n",
    "    org_source = json.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "data = {'version': 'v2.0', 'data': []}\n",
    "text = None\n",
    "for i, passage in enumerate(org_source):\n",
    "    txt = passage[0]\n",
    "    qus = passage[1]\n",
    "    st_pos = txt.lower().find(passage[2].lower())\n",
    "    ans = passage[2] if st_pos != -1 else ''\n",
    "    is_impossible = st_pos == -1\n",
    "    id = str(i) + str(idx)\n",
    "    if txt != text:\n",
    "        data['data'].append({'title': str(i), 'paragraphs': [\n",
    "            {'qas':[{'question': qus, 'id': id, 'answers': [{'text': ans, 'answer_start': st_pos}], 'is_impossible': is_impossible}], 'context':txt}]})\n",
    "        idx += 1\n",
    "        text = txt\n",
    "    else:\n",
    "        data['data'][idx]['paragraphs'][0]['qas'].append({'question': qus, 'id': id, 'answers': [{'text': ans, 'answer_start': st_pos}], 'is_impossible': is_impossible})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'id', 'answers', 'is_impossible'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]['paragraphs'][0]['qas'][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-v2.0-vi.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
